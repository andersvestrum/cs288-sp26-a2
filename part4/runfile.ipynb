{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bec43be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e7879d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required packages...\n",
      "  Installing torch... ✓\n",
      "  Installing tiktoken... ✓\n",
      "  Installing psutil... ✓\n",
      "  Installing regex... ✓\n",
      "  Installing pytest... ✓\n",
      "  Installing numpy... ✓\n",
      "  Installing einops... ✓\n",
      "  Installing datasets... ✓\n",
      "  Installing tqdm... ✓\n",
      "\n",
      "✓ All packages installed successfully!\n",
      "✓ PyTorch version: 2.9.0+cu128\n",
      "✓ CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"Installing required packages...\")\n",
    "\n",
    "# Install torch first with proper index\n",
    "print(\"  Installing torch...\", end=\" \", flush=True)\n",
    "subprocess.check_call([\n",
    "    sys.executable, \"-m\", \"pip\", \"install\", \n",
    "    \"--index-url\", \"https://download.pytorch.org/whl/cpu\",\n",
    "    \"torch\", \"-q\"\n",
    "])\n",
    "print(\"✓\")\n",
    "\n",
    "# Install other packages\n",
    "packages = [\n",
    "    \"tiktoken\",\n",
    "    \"psutil\",\n",
    "    \"regex\",\n",
    "    \"pytest\",\n",
    "    \"numpy\",\n",
    "    \"einops\",\n",
    "    \"datasets\",\n",
    "    \"tqdm\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"  Installing {package}...\", end=\" \", flush=True)\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "    print(\"✓\")\n",
    "\n",
    "print(\"\\n✓ All packages installed successfully!\")\n",
    "\n",
    "# Verify torch installation\n",
    "import torch\n",
    "print(f\"✓ PyTorch version: {torch.__version__}\")\n",
    "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d191d8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Running in Jupyter - using notebook-optimized progress bars\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Configure tqdm to work better in notebooks\n",
    "import sys\n",
    "if 'ipykernel' in sys.modules:\n",
    "    from tqdm.notebook import tqdm as tqdm_notebook\n",
    "    print(\"✓ Running in Jupyter - using notebook-optimized progress bars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a51b526d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'cs288-sp26-a2'...\n",
      "remote: Enumerating objects: 183, done.\u001b[K\n",
      "remote: Counting objects: 100% (183/183), done.\u001b[K\n",
      "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
      "remote: Total 183 (delta 81), reused 151 (delta 49), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (183/183), 2.89 MiB | 29.26 MiB/s, done.\n",
      "Resolving deltas: 100% (81/81), done.\n",
      "/content/cs288-sp26-a2\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "!rm -rf cs288-sp26-a2\n",
    "!git clone https://github.com/andersvestrum/cs288-sp26-a2.git\n",
    "%cd cs288-sp26-a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca4e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CS288 Part 4 - Dataset Setup\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Downloading TinyStories dataset...\n",
      "============================================================\n",
      "Total stories: 2,119,719\n",
      "  Processed 100,000 stories...\n",
      "  Processed 200,000 stories...\n",
      "  Processed 300,000 stories...\n",
      "  Processed 400,000 stories...\n",
      "  Processed 500,000 stories...\n",
      "  Processed 600,000 stories...\n",
      "  Processed 700,000 stories...\n",
      "  Processed 800,000 stories...\n",
      "  Processed 900,000 stories...\n",
      "  Processed 1,000,000 stories...\n",
      "  Processed 1,100,000 stories...\n",
      "  Processed 1,200,000 stories...\n",
      "  Processed 1,300,000 stories...\n",
      "  Processed 1,400,000 stories...\n",
      "  Processed 1,500,000 stories...\n",
      "  Processed 1,600,000 stories...\n",
      "  Processed 1,700,000 stories...\n",
      "  Processed 1,800,000 stories...\n",
      "  Processed 1,900,000 stories...\n",
      "  Processed 2,000,000 stories...\n",
      "  Processed 2,100,000 stories...\n",
      "\n",
      "Saved to: /content/cs288-sp26-a2/part4/fixtures/tinystories_full.txt\n",
      "File size: 1845.1 MB\n",
      "Also created 100k subset: /content/cs288-sp26-a2/part4/fixtures/tinystories_100k.txt\n",
      "\n",
      "============================================================\n",
      "Downloading SQuAD v1.1 dataset...\n",
      "============================================================\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Training examples: 87,599\n",
      "Validation examples: 10,570\n",
      "\n",
      "Converting to multiple-choice format...\n"
     ]
    }
   ],
   "source": [
    "!python part4/setup_datasets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c317d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: can't open file '/content/cs288-sp26-a2/part4/augment_qa_data.py': [Errno 2] No such file or directory\n",
      "============================================================\n",
      "CS288 Part 4 - Baseline Training\n",
      "============================================================\n",
      "\n",
      "Configuration: small\n",
      "Device: cuda\n",
      "\n",
      "============================================================\n",
      "STEP 1: Training BPE Tokenizer\n",
      "============================================================\n",
      "Input: /content/cs288-sp26-a2/part4/fixtures/tinystories_100k.txt\n",
      "Vocab size: 4096\n",
      "Special tokens: ['<|endoftext|>', '<|pad|>']\n",
      "\n",
      "Tokenizer trained!\n",
      "  Vocab size: 4096\n",
      "  Merges: 3838\n",
      "\n",
      "Test encoding:\n",
      "  Input:   'Once upon a time, there was a little girl.'\n",
      "  Tokens:  11 tokens\n",
      "  Decoded: 'Once upon a time, there was a little girl.'\n",
      "\n",
      "============================================================\n",
      "STEP 2: Pretraining Language Model\n",
      "============================================================\n",
      "\n",
      "Model architecture:\n",
      "  d_model: 256\n",
      "  num_layers: 6\n",
      "  num_heads: 8\n",
      "  d_ff: 1024\n",
      "  context_length: 512\n",
      "  Parameters: 8,391,936\n",
      "\n",
      "Training data:\n",
      "  File: /content/cs288-sp26-a2/part4/fixtures/tinystories_100k.txt\n",
      "  Documents: 88670\n",
      "  Batches/epoch: 2771\n",
      "\n",
      "Training for 3 epoch(s)...\n",
      "  Training 3 epochs, 2771 batches/epoch\n",
      "  Epoch 1/3: loss=2.7517 (201.2s)\n",
      "  Epoch 2/3: loss=1.9493 (199.7s)\n",
      "  Epoch 3/3: loss=1.8095 (199.9s)\n",
      "\n",
      "Generation test:\n",
      "  'Once upon a time' -> 'Once upon a time, there was a little girl named Lily. She loved to play outside ...'\n",
      "  'The little dog' -> 'The little dog was so happy that he had helped the little girl. From that day on...'\n",
      "\n",
      "============================================================\n",
      "STEP 3: Fine-tuning for Multiple-Choice QA\n",
      "============================================================\n",
      "\n",
      "QA model parameters: 8,392,192\n",
      "\n",
      "Training data: /content/cs288-sp26-a2/part4/fixtures/squad_train.json\n",
      "Training examples: 10000\n",
      "Batches/epoch: 313\n",
      "\n",
      "Fine-tuning for 10 epoch(s)...\n",
      "  Training 10 epochs, 313 batches/epoch\n",
      "  Epoch 1/10: loss=1.3320 (143.1s)\n",
      "  Epoch 2/10: loss=1.0410 (145.1s)\n",
      "  Epoch 3/10: loss=0.8431 (145.1s)\n",
      "  Epoch 4/10: loss=0.6297 (144.4s)\n",
      "  Epoch 5/10: loss=0.3881 (144.0s)\n",
      "  Epoch 6/10: loss=0.1764 (141.2s)\n",
      "  Epoch 7/10: loss=0.0803 (140.2s)\n",
      "  Epoch 8/10: loss=0.0230 (139.9s)\n",
      "  Epoch 9/10: loss=0.0072 (139.9s)\n",
      "  Epoch 10/10: loss=0.0026 (139.5s)\n",
      "\n",
      "============================================================\n",
      "STEP 4: Evaluating Prompting (multiple strategies)\n",
      "============================================================\n",
      "\n",
      "Validation examples: 2000\n",
      "  token + basic: 24.60%\n",
      "  token + simple: 22.75%\n",
      "  token + instruction: 25.55%\n",
      "  token + direct: 23.80%\n",
      "  choice_ll + basic: 24.45%\n",
      "  choice_ll + simple: 24.45%\n",
      "  choice_ll + instruction: 24.45%\n",
      "  choice_ll + direct: 24.45%\n",
      "  choice_ll + basic + 1-shot: 24.45%\n",
      "  choice_ll + simple + 1-shot: 24.45%\n",
      "  choice_ll + basic + 3-shot: 24.45%\n",
      "  choice_ll + simple + 3-shot: 24.45%\n",
      "  choice_ll + basic + 5-shot: 24.45%\n",
      "  choice_ll + simple + 5-shot: 24.45%\n",
      "\n",
      "  BEST: token + instruction -> 25.55%\n",
      "  Random baseline: 25.00%\n",
      "\n",
      "============================================================\n",
      "STEP 5: Evaluating Fine-tuned Model\n",
      "============================================================\n",
      "\n",
      "Validation examples: 2000\n",
      "\n",
      "Fine-tuned model accuracy: 52.10%\n",
      "Random baseline: 25.00%\n",
      "\n",
      "============================================================\n",
      "STEP 6: Generating TEST SET predictions for submission\n",
      "============================================================\n",
      "\n",
      "Test examples: 1000\n",
      "\n",
      "Generating fine-tuned test predictions...\n",
      "  Fine-tuned test accuracy: 54.50%\n",
      "\n",
      "Generating prompting test predictions using best dev strategy: token + instruction\n",
      "  Prompting test accuracy: 26.10%\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "\n",
      "Configuration: small\n",
      "Model parameters: 8,391,936\n",
      "\n",
      "DEV SET results (used for strategy selection):\n",
      "  Prompting approach:    25.55%\n",
      "  Classification head:   52.10%\n",
      "\n",
      "TEST SET results (submitted to Gradescope):\n",
      "  Prompting approach:    26.10%\n",
      "  Classification head:   54.50%\n",
      "  Random baseline:       25.00%\n",
      "\n",
      "  Prompting boost over fine-tuned (test): -28.40%\n",
      "  (Prompting should beat fine-tuned model)\n",
      "\n",
      "TEST predictions saved to:\n",
      "  /content/cs288-sp26-a2/part4/outputs/finetuned_predictions.json\n",
      "  /content/cs288-sp26-a2/part4/outputs/prompting_predictions.json\n",
      "\n",
      "============================================================\n",
      "ESTIMATED GRADING (based on test set)\n",
      "============================================================\n",
      "\n",
      "Fine-tuned score:  100% (30%=0pts, 50%=full)\n",
      "Prompting score:   0% (0% boost=0pts, 4% boost=full)\n",
      "Total Part 4:      50%\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Generate augmented QA training data first\n",
    "!python part4/augment_qa_data.py\n",
    "\n",
    "# Train with --small config (uses augmented in-domain QA data)\n",
    "!python part4/train_baseline.py --small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd35f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "✓ Copied finetuned_predictions.json to Google Drive\n",
      "✓ Copied prompting_predictions.json to Google Drive\n",
      "\n",
      "Files saved to: /content/drive/MyDrive/cs288-a2-outputs\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import shutil, os\n",
    "\n",
    "src_dir = '/content/cs288-sp26-a2/part4/outputs'\n",
    "dst_dir = '/content/drive/MyDrive/cs288-a2-outputs'\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "for name in ['finetuned_predictions.json', 'prompting_predictions.json']:\n",
    "    src = os.path.join(src_dir, name)\n",
    "    dst = os.path.join(dst_dir, name)\n",
    "    shutil.copy2(src, dst)\n",
    "    print(f\"✓ Copied {name} to Google Drive\")\n",
    "\n",
    "print(f\"\\nFiles saved to: {dst_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
